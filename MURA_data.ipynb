{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MURA_data.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ondraperny/BI-BPR-2019/blob/master/MURA_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nU19OXW480YR",
        "colab_type": "text"
      },
      "source": [
        "# Mura dataset\n",
        "Currently for testing purposes, just part of dataset is used. Specifically XR_HUMERUS data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mbw0u9Xp2wwL",
        "colab_type": "code",
        "outputId": "54aa12e2-7376-4460-a456-49c3f6427c7f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83
        }
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import keras\n",
        "import keras.backend as k\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import os\n",
        "from glob import glob\n",
        "%matplotlib inline"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "07fIaB9DJBZ7",
        "colab_type": "code",
        "outputId": "205aba5b-b5f2-4c3b-af7e-f8817db1b356",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Cloud\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "PATH=\"/content/drive/My Drive/SKOLA/Bachelor_work/XR_HUMERUS/\""
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RuuN1H4VJG5j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Local\n",
        "# PATH=\"C:/DEV/Bak/XR_HUMERUS/\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GDeg8JQj5Ehf",
        "colab_type": "text"
      },
      "source": [
        "##  Constants declaration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lt_lzmQQ5DDC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "PATH_TRAIN = PATH + 'train'\n",
        "PATH_VALID = PATH + 'valid'\n",
        "IMG_SIZE=(224,224)\n",
        "INPUT_SHAPE = (*IMG_SIZE, 3)\n",
        "BATCH_SIZE = 128\n",
        "NUMBER_CLASSES = 2\n",
        "NUMBER_EPOCHS = 15\n",
        "NUMBER_STEPS_PER_EPOCH = 62\n",
        "NUMBER_VALIDATION_STEPS = 62"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XyaNFRPd87u9",
        "colab_type": "text"
      },
      "source": [
        "## Data augmentation\n",
        "Currently image augmentation will be done by parameters of ImageDataGenerator.\n",
        "If in future this solution will be insufficient, I will change it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B0SF2y318g9b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def ImageDataGenerator_def():\n",
        "  datagen = ImageDataGenerator(\n",
        "    # featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "    # samplewise_center=False,  # set each sample mean to 0\n",
        "    # featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
        "    # samplewise_std_normalization=False,  # divide each input by its std\n",
        "    # zca_whitening=False,  # apply ZCA whitening\n",
        "    # zca_epsilon=1e-06,  # epsilon for ZCA whitening\n",
        "    # rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "    # # randomly shift images horizontally (fraction of total width)\n",
        "    # width_shift_range=0.1,\n",
        "    # # randomly shift images vertically (fraction of total height)\n",
        "    # height_shift_range=0.1,\n",
        "    # shear_range=0.,  # set range for random shear\n",
        "    # zoom_range=0.,  # set range for random zoom\n",
        "    # channel_shift_range=0.,  # set range for random channel shifts\n",
        "    # # set mode for filling points outside the input boundaries\n",
        "    # fill_mode='nearest',\n",
        "    # cval=0.,  # value used for fill_mode = \"constant\"\n",
        "    # horizontal_flip=True,  # randomly flip images\n",
        "    # vertical_flip=False,  # randomly flip images\n",
        "    # set rescaling factor (applied before any other transformation)\n",
        "    rescale=1. / 255,\n",
        "    # # set function that will be applied on each input\n",
        "    # preprocessing_function=None,\n",
        "    # # image data format, either \"channels_first\" or \"channels_last\"\n",
        "    # data_format=None,\n",
        "    # # fraction of images reserved for validation (strictly between 0 and 1)\n",
        "    # validation_split=0.0\n",
        "  )\n",
        "  return datagen\n",
        "\n",
        "def load_from_directory(dir_path):\n",
        "  '''Load images from directory while transforming data (based on parameters),\n",
        "  contain other parameters for data augmentation'''\n",
        "  batches = data_generator.flow_from_directory(\n",
        "    # path to target directory from which data will be loaded\n",
        "    dir_path,\n",
        "    # resize all input images to IMG_SIZE\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='binary',\n",
        "  )\n",
        "  return batches"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v-fmS0tr9WU7",
        "colab_type": "code",
        "outputId": "6452c7b2-d136-40a7-95bd-fd3b3fab6f32",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "data_generator = ImageDataGenerator_def()\n",
        "\n",
        "train_batches = load_from_directory(PATH_TRAIN)\n",
        "valid_batches = load_from_directory(PATH_VALID)\n",
        "\n",
        "print(\"Found indices: \")\n",
        "print(train_batches.class_indices)\n",
        "# print(train_batches.class_indices)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1272 images belonging to 2 classes.\n",
            "Found 288 images belonging to 2 classes.\n",
            "Found indices: \n",
            "{'train_negative': 0, 'train_positive': 1}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i1v5wG3o8yNc",
        "colab_type": "text"
      },
      "source": [
        "## Functions\n",
        "Next block contains definitions of function for following code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0dBmWDHA8xOE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def label_to_string(label):\n",
        "  '''Map label value to descriptive string'''\n",
        "  if(label[0] == 0):\n",
        "    return \"Negative\"\n",
        "  else:\n",
        "    return \"Positive\"\n",
        "\n",
        "def show_sample_images():\n",
        "  '''Show one batch of training images'''\n",
        "  images, labels = train_batches.next()\n",
        "  plt.figure(figsize=(25,25))\n",
        "  for i in range(BATCH_SIZE):\n",
        "    plt.subplot(1,BATCH_SIZE,i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    # plt.title(label_to_string(labels[i]))\n",
        "    plt.imshow(images[i].astype('uint8'), cmap=plt.cm.binary)\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z7QB-EFKyiD8",
        "colab_type": "code",
        "outputId": "ff4ce85b-515f-4b99-e842-8a1a654f7b0f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 43
        }
      },
      "source": [
        "show_sample_images()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABYQAAAAaCAYAAAAHf1jWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAB70lEQVR4nO3dQW7CMBAF0LjiCN33/sdizx3cBWVR\naEVGOCSeeW9ZfYkoY4zya0HrvS8AAAAAAOT3sfcFAAAAAADwHgphAAAAAIAiFMIAAAAAAEUohAEA\nAAAAilAIAwAAAAAUcYqEW2t9Ta733rbIBlyWZfkc/fqy22YDzDd5NsBamDAbYL7JswHWwoTZAPOd\nMBuwer6R7BHugWyY+U6YDTDf5NkAa2HCbID5Tpq9/1vWE8LnvS+ATZkvN9ZCbkPm29rDZx/z8V7P\nzXwP7sV9NDJfayE3883NfLmxFnIz3ySyFsIAAMAAvY8+XAQAwJ4UwgfmVBvA63rv9lMAAAD4oRA+\nMKcxAMZRCgMAACN5xmBWCuFJ2GQA1rNnAgAAW3OQj3cZ/YyrEJ6ETQZgvfuvibCHAgAAMKvRz7QK\n4Yk5AQewnlIYAAAAFMJTU24A/M+PyQEAAMCjUzB/WZbl/CTztXH2We6WPcK1ysaz5itrLdTIvmW+\nf/zj7Ej3QPbKez131nxzZ0fON5I90j2QvTLf3FnzlbUWamTNN3f2l+aUKQAAAABADb4yAgAAAACg\nCIUwAAAAAEARCmEAAAAAgCIUwgAAAAAARSiEAQAAAACKUAgDAAAAABShEAYAAAAAKEIhDAAAAABQ\nhEIYAAAAAKCIb7zg0LciUEbkAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 1800x1800 with 128 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WznMKC7APFCX",
        "colab_type": "text"
      },
      "source": [
        "## Model definitions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9w7QjO3FPJuX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.optimizers import SGD\n",
        "\n",
        "def simple_deep_CNN():\n",
        "  model = Sequential()\n",
        "  model.add(Conv2D(32, (3, 3), padding='same', input_shape=INPUT_SHAPE))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(Conv2D(32, (3, 3)))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  model.add(Dropout(0.25))\n",
        "  \n",
        "  model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(Conv2D(64, (3, 3)))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  model.add(Dropout(0.25))\n",
        "\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(512))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(Dropout(0.5))\n",
        "  model.add(Dense(NUMBER_CLASSES))\n",
        "  model.add(Activation('softmax'))\n",
        "  model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "  return model\n",
        "\n",
        "def model2():\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=INPUT_SHAPE))\n",
        "\tmodel.add(MaxPooling2D((2, 2)))\n",
        "\tmodel.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "\tmodel.add(MaxPooling2D((2, 2)))\n",
        "\tmodel.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "\tmodel.add(MaxPooling2D((2, 2)))\n",
        "\tmodel.add(Flatten())\n",
        "\tmodel.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
        "\tmodel.add(Dense(1, activation='sigmoid'))\n",
        "\t# compile model\n",
        "\topt = SGD(lr=0.001, momentum=0.9)\n",
        "\tmodel.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\treturn model\n",
        "\n",
        "def model_def():\n",
        "  model = Sequential()\n",
        "  model.add(Conv2D(32, (3, 3), activation='relu', input_shape=INPUT_SHAPE))\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(2, activation='softmax'))\n",
        "  model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XlF3BkGpcA8M",
        "colab_type": "code",
        "outputId": "19c8a5b3-de50-41b9-ac9c-97ae2588e9cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 495
        }
      },
      "source": [
        "model = model2()\n",
        "model.summary()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_4 (Conv2D)            (None, 224, 224, 32)      896       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 112, 112, 32)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 112, 112, 64)      18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 56, 56, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 56, 56, 128)       73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2 (None, 28, 28, 128)       0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 100352)            0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 128)               12845184  \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 12,938,561\n",
            "Trainable params: 12,938,561\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RLu4W0VHdw8b",
        "colab_type": "code",
        "outputId": "60a23209-1f4a-4b80-d7dd-3f19d798f360",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 770
        }
      },
      "source": [
        "model.fit_generator(train_batches,\n",
        "                    steps_per_epoch= len(train_batches),\n",
        "                    validation_data = valid_batches,\n",
        "                    validation_steps = len(valid_batches),\n",
        "                    epochs = NUMBER_EPOCHS)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "10/10 [==============================] - 112s 11s/step - loss: 0.7106 - acc: 0.5485 - val_loss: 0.7825 - val_acc: 0.5000\n",
            "Epoch 2/15\n",
            "10/10 [==============================] - 109s 11s/step - loss: 0.7010 - acc: 0.5584 - val_loss: 0.7190 - val_acc: 0.5104\n",
            "Epoch 3/15\n",
            "10/10 [==============================] - 112s 11s/step - loss: 0.6780 - acc: 0.5746 - val_loss: 0.6681 - val_acc: 0.5972\n",
            "Epoch 4/15\n",
            "10/10 [==============================] - 112s 11s/step - loss: 0.6511 - acc: 0.6135 - val_loss: 0.6625 - val_acc: 0.6354\n",
            "Epoch 5/15\n",
            "10/10 [==============================] - 112s 11s/step - loss: 0.6378 - acc: 0.6448 - val_loss: 0.6603 - val_acc: 0.6285\n",
            "Epoch 6/15\n",
            "10/10 [==============================] - 112s 11s/step - loss: 0.6208 - acc: 0.6613 - val_loss: 0.6548 - val_acc: 0.6146\n",
            "Epoch 7/15\n",
            "10/10 [==============================] - 112s 11s/step - loss: 0.6225 - acc: 0.6493 - val_loss: 0.6693 - val_acc: 0.5556\n",
            "Epoch 8/15\n",
            "10/10 [==============================] - 112s 11s/step - loss: 0.6070 - acc: 0.7000 - val_loss: 0.6524 - val_acc: 0.6424\n",
            "Epoch 9/15\n",
            "10/10 [==============================] - 112s 11s/step - loss: 0.5904 - acc: 0.6901 - val_loss: 0.6520 - val_acc: 0.6146\n",
            "Epoch 10/15\n",
            "10/10 [==============================] - 113s 11s/step - loss: 0.5812 - acc: 0.7006 - val_loss: 0.6518 - val_acc: 0.6528\n",
            "Epoch 11/15\n",
            "10/10 [==============================] - 112s 11s/step - loss: 0.5757 - acc: 0.7142 - val_loss: 0.6581 - val_acc: 0.6458\n",
            "Epoch 12/15\n",
            "10/10 [==============================] - 111s 11s/step - loss: 0.5752 - acc: 0.7020 - val_loss: 0.6593 - val_acc: 0.5868\n",
            "Epoch 13/15\n",
            "10/10 [==============================] - 111s 11s/step - loss: 0.5617 - acc: 0.7248 - val_loss: 0.6493 - val_acc: 0.6250\n",
            "Epoch 14/15\n",
            "10/10 [==============================] - 111s 11s/step - loss: 0.5453 - acc: 0.7245 - val_loss: 0.6609 - val_acc: 0.6285\n",
            "Epoch 15/15\n",
            "10/10 [==============================] - 110s 11s/step - loss: 0.5382 - acc: 0.7342 - val_loss: 0.6609 - val_acc: 0.6111\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f1e5a848a90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_mt7ERQohNJk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len(train_batches)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nDXGAwXImI4B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}